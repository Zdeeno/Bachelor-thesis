
\section{Brief introduction to RL}
At first we have to define an environment where agent can run. Environment can be described as Markov decision process (MDP), where $s_t \in S$ is state from set of possible states $S$ in which is environment located in time $t$. Agent can observe environment's state and take action accordingly. Action is a transition between states so every action $a_t \in A$ moves environment from $s_t$ to $s_{t+1}$. Environment evaluates every action and return appropriate reward $r_t$. In RL is $A$ often called action space and $S$ observation space.  